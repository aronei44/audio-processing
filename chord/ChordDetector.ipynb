{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torchaudio\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_LENGTH = 256\n",
    "TRAINING_DATA_PATH = 'data/Training'\n",
    "TESTING_DATA_PATH = 'data/Test'\n",
    "BATCH_SIZE = 32\n",
    "INPUT_SIZE = TARGET_LENGTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_file_list(dir, item_list = []):\n",
    "    for item in os.listdir(dir):\n",
    "        path = os.path.join(dir, item)\n",
    "        if os.path.isdir(path):\n",
    "            items = get_file_list(path, item_list)\n",
    "            for item in items:\n",
    "                item_list.append(item)\n",
    "        else:\n",
    "            item_list.append(path)\n",
    "    return list(set(item_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list = get_file_list(TRAINING_DATA_PATH)\n",
    "test_list = get_file_list(TESTING_DATA_PATH)\n",
    "class_list = os.listdir(TRAINING_DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDataset(item_list):\n",
    "    dataset = []\n",
    "    for item in tqdm(item_list):\n",
    "        # Load an audio file\n",
    "        waveform, sample_rate = torchaudio.load(item, normalize=True)\n",
    "\n",
    "        # Extract pitch using Harmonic Product Spectrum (HPS)\n",
    "        pitch = torchaudio.functional.detect_pitch_frequency(waveform, sample_rate, frame_time=0.02)\n",
    "        label = os.path.basename(os.path.dirname(item))\n",
    "        if pitch.shape[0] > 1:\n",
    "            pitch = torch.mean(pitch, dim=0, keepdim=True)\n",
    "        pitch = pitch[0]\n",
    "        dataset.append((\n",
    "            pitch.max().numpy(),\n",
    "            pitch.min().numpy(),\n",
    "            pitch.mean().numpy(),\n",
    "            pitch.std().numpy(),\n",
    "            pitch.median().numpy(), \n",
    "            len(pitch),\n",
    "            pitch.max().numpy() - pitch.min().numpy(),\n",
    "            label,\n",
    "            class_list.index(label)\n",
    "        ))\n",
    "    df = pd.DataFrame(dataset, columns=['pitch_max', 'pitch_min', 'pitch_mean', 'pitch_std', 'pitch_median','pitch_length', 'pitch_range', 'label', 'label_class'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1440/1440 [01:54<00:00, 12.62it/s]\n",
      "100%|██████████| 1760/1760 [02:05<00:00, 13.99it/s]\n"
     ]
    }
   ],
   "source": [
    "train_data = getDataset(train_list)\n",
    "test_data = getDataset(test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.concat([train_data, test_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = all_data[['pitch_max', 'pitch_min', 'pitch_mean', 'pitch_std', 'pitch_median',\n",
    "         'pitch_length', 'pitch_range']], all_data['label_class']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=all_data['label_class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    (\"prep\", StandardScaler()),\n",
    "    (\"algo\", KNeighborsClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 200 candidates, totalling 600 fits\n"
     ]
    }
   ],
   "source": [
    "parameter = {\n",
    "    \"algo__n_neighbors\": range(1, 51),\n",
    "    \"algo__weights\": ['uniform','distance'],\n",
    "    \"algo__p\": [1,2]\n",
    "}\n",
    "\n",
    "model = GridSearchCV(pipeline, parameter, cv=3, n_jobs=-1, verbose=1)\n",
    "model.fit(X_train, y_train)\n",
    "best_params_ = model.best_params_\n",
    "best_score_ = model.best_score_\n",
    "score_test = model.score(X_test, y_test)\n",
    "score_train = model.score(X_train, y_train)\n",
    "logs.append([\n",
    "    best_params_,\n",
    "    best_score_,\n",
    "    score_test,\n",
    "    score_train,\n",
    "    \"KNeighborsClassifier\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(model, open('models/knnc.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    (\"prep\", StandardScaler()),\n",
    "    (\"algo\", RandomForestClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 361 candidates, totalling 1083 fits\n"
     ]
    }
   ],
   "source": [
    "parameter = {\n",
    "    \"algo__max_samples\": range(1, 20),\n",
    "    \"algo__max_depth\": range(1,20)\n",
    "}\n",
    "\n",
    "model = GridSearchCV(pipeline, parameter, cv=3, n_jobs=-1, verbose=1)\n",
    "model.fit(X_train, y_train)\n",
    "best_params_ = model.best_params_\n",
    "best_score_ = model.best_score_\n",
    "score_test = model.score(X_test, y_test)\n",
    "score_train = model.score(X_train, y_train)\n",
    "logs.append([\n",
    "    best_params_,\n",
    "    best_score_,\n",
    "    score_test,\n",
    "    score_train,\n",
    "    \"RandomForestClassifier\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(model, open('models/rfc.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    (\"prep\", StandardScaler()),\n",
    "    (\"algo\", SVC())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
     ]
    }
   ],
   "source": [
    "parameter = {\n",
    "    \"algo__tol\": [0.0001, 0.001, 0.01, 0.1],\n",
    "    \"algo__C\": [1.0, 2.0]\n",
    "}\n",
    "\n",
    "model = GridSearchCV(pipeline, parameter, cv=3, n_jobs=-1, verbose=1)\n",
    "model.fit(X_train, y_train)\n",
    "best_params_ = model.best_params_\n",
    "best_score_ = model.best_score_\n",
    "score_test = model.score(X_test, y_test)\n",
    "score_train = model.score(X_train, y_train)\n",
    "logs.append([\n",
    "    best_params_,\n",
    "    best_score_,\n",
    "    score_test,\n",
    "    score_train,\n",
    "    \"SVC\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(model, open('models/svc.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    (\"prep\", StandardScaler()),\n",
    "    (\"algo\", LogisticRegression(multi_class='multinomial'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
     ]
    }
   ],
   "source": [
    "parameter = {\n",
    "    \"algo__tol\": [0.0001, 0.001, 0.01, 0.1],\n",
    "    \"algo__C\": [1.0, 2.0]\n",
    "}\n",
    "\n",
    "model = GridSearchCV(pipeline, parameter, cv=3, n_jobs=-1, verbose=1)\n",
    "model.fit(X_train, y_train)\n",
    "best_params_ = model.best_params_\n",
    "best_score_ = model.best_score_\n",
    "score_test = model.score(X_test, y_test)\n",
    "score_train = model.score(X_train, y_train)\n",
    "logs.append([\n",
    "    best_params_,\n",
    "    best_score_,\n",
    "    score_test,\n",
    "    score_train,\n",
    "    \"LogisticRegression\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(model, open('models/lr.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    (\"prep\", StandardScaler()),\n",
    "    (\"algo\", MLPClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
     ]
    }
   ],
   "source": [
    "parameter = {\n",
    "    \"algo__tol\": [0.0001, 0.001, 0.01, 0.1],\n",
    "    \"algo__max_iter\": [1000, 2000]\n",
    "}\n",
    "\n",
    "model = GridSearchCV(pipeline, parameter, cv=3, n_jobs=-1, verbose=1)\n",
    "model.fit(X_train, y_train)\n",
    "best_params_ = model.best_params_\n",
    "best_score_ = model.best_score_\n",
    "score_test = model.score(X_test, y_test)\n",
    "score_train = model.score(X_train, y_train)\n",
    "logs.append([\n",
    "    best_params_,\n",
    "    best_score_,\n",
    "    score_test,\n",
    "    score_train,\n",
    "    \"MLPClassifier\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(model, open('models/mlp.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    (\"prep\", StandardScaler()),\n",
    "    (\"algo\", GradientBoostingClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 70 candidates, totalling 210 fits\n"
     ]
    }
   ],
   "source": [
    "parameter = {\n",
    "    \"algo__subsample\": [.1,.2,.3,.4,.5, .6, .7, .8, .9, 1.0],\n",
    "    \"algo__max_depth\": range(1,8)\n",
    "}\n",
    "\n",
    "model = GridSearchCV(pipeline, parameter, cv=3, n_jobs=-1, verbose=1)\n",
    "model.fit(X_train, y_train)\n",
    "best_params_ = model.best_params_\n",
    "best_score_ = model.best_score_\n",
    "score_test = model.score(X_test, y_test)\n",
    "score_train = model.score(X_train, y_train)\n",
    "logs.append([\n",
    "    best_params_,\n",
    "    best_score_,\n",
    "    score_test,\n",
    "    score_train,\n",
    "    \"GradientBoostingClassifier\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(model, open('models/gbc.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>best_params</th>\n",
       "      <th>best_score</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_train</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'algo__n_neighbors': 1, 'algo__p': 1, 'algo__...</td>\n",
       "      <td>0.677730</td>\n",
       "      <td>0.817187</td>\n",
       "      <td>0.970313</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'algo__max_depth': 11, 'algo__max_samples': 19}</td>\n",
       "      <td>0.445310</td>\n",
       "      <td>0.439063</td>\n",
       "      <td>0.471484</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'algo__C': 2.0, 'algo__tol': 0.01}</td>\n",
       "      <td>0.203904</td>\n",
       "      <td>0.218750</td>\n",
       "      <td>0.276953</td>\n",
       "      <td>SVC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'algo__C': 1.0, 'algo__tol': 0.1}</td>\n",
       "      <td>0.179291</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>0.194531</td>\n",
       "      <td>LogisticRegression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'algo__max_iter': 2000, 'algo__tol': 0.0001}</td>\n",
       "      <td>0.355855</td>\n",
       "      <td>0.371875</td>\n",
       "      <td>0.439063</td>\n",
       "      <td>MLPClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'algo__max_depth': 6, 'algo__subsample': 0.6}</td>\n",
       "      <td>0.822655</td>\n",
       "      <td>0.885938</td>\n",
       "      <td>0.974609</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         best_params  best_score  score_test  \\\n",
       "0  {'algo__n_neighbors': 1, 'algo__p': 1, 'algo__...    0.677730    0.817187   \n",
       "1   {'algo__max_depth': 11, 'algo__max_samples': 19}    0.445310    0.439063   \n",
       "2                {'algo__C': 2.0, 'algo__tol': 0.01}    0.203904    0.218750   \n",
       "3                 {'algo__C': 1.0, 'algo__tol': 0.1}    0.179291    0.175000   \n",
       "4      {'algo__max_iter': 2000, 'algo__tol': 0.0001}    0.355855    0.371875   \n",
       "5     {'algo__max_depth': 6, 'algo__subsample': 0.6}    0.822655    0.885938   \n",
       "\n",
       "   score_train                       model  \n",
       "0     0.970313        KNeighborsClassifier  \n",
       "1     0.471484      RandomForestClassifier  \n",
       "2     0.276953                         SVC  \n",
       "3     0.194531          LogisticRegression  \n",
       "4     0.439063               MLPClassifier  \n",
       "5     0.974609  GradientBoostingClassifier  "
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_df = pd.DataFrame(logs, columns=['best_params', 'best_score', 'score_test', 'score_train', 'model'])\n",
    "log_df.to_csv('logs.csv', index=False)\n",
    "log_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
